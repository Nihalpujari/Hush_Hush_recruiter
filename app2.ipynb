{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aaed646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "TOP 3 DEVELOPER CANDIDATES\n",
      "################################################################################\n",
      "1. The Devastator\n",
      "   BASIS: Selected for high documentation standards. Maintained an average Usability score of 9.4/10 across 504 projects, ensuring clean code handovers.\n",
      "\n",
      "2. fedesoriano\n",
      "   BASIS: Selected for high documentation standards. Maintained an average Usability score of 10.0/10 across 23 projects, ensuring clean code handovers.\n",
      "\n",
      "3. MarÃ­lia Prata\n",
      "   BASIS: Selected for high documentation standards. Maintained an average Usability score of 10.0/10 across 23 projects, ensuring clean code handovers.\n",
      "\n",
      "\n",
      "################################################################################\n",
      "TOP 3 SENIOR DEVELOPER CANDIDATES\n",
      "################################################################################\n",
      "1. Larxel\n",
      "   BASIS: Selected for community authority and peer vetting. Earned 129 medal points and 9262 peer upvotes, establishing them as a gold-standard reference in the industry.\n",
      "\n",
      "2. Sourav Banerjee\n",
      "   BASIS: Selected for community authority and peer vetting. Earned 88 medal points and 2783 peer upvotes, establishing them as a gold-standard reference in the industry.\n",
      "\n",
      "3. The Devastator\n",
      "   BASIS: Selected for community authority and peer vetting. Earned 72 medal points and 4816 peer upvotes, establishing them as a gold-standard reference in the industry.\n",
      "\n",
      "\n",
      "################################################################################\n",
      "TOP 3 SOLUTION ARCHITECT CANDIDATES\n",
      "################################################################################\n",
      "1. Pascal Bliem\n",
      "   BASIS: Selected for scale mastery and structural complexity. Successfully managed 3999569 individual files across a total footprint of 14.0 GB data.\n",
      "\n",
      "2. Sanskar Hasija\n",
      "   BASIS: Selected for scale mastery and structural complexity. Successfully managed 1377708 individual files across a total footprint of 21.0 GB data.\n",
      "\n",
      "3. Alexei Matusevski\n",
      "   BASIS: Selected for scale mastery and structural complexity. Successfully managed 1211666 individual files across a total footprint of 101.0 GB data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# --- Fix Truncation Issue ---\n",
    "# These settings ensure the console displays long strings (like for Architects) fully.\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# 1. Load Data\n",
    "try:\n",
    "    df = pd.read_csv('kaggle-preprocessed.csv', index_col=0)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'kaggle-preprocessed.csv' not found. Please ensure the file is in the same directory.\")\n",
    "    exit()\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA CLEANING & NOISE REDUCTION\n",
    "# ==========================================\n",
    "\n",
    "# Standardizing 'Size' (Handles noise from mixed units KB, MB, GB, B)\n",
    "def standardize_size_to_mb(val):\n",
    "    val = str(val).upper()\n",
    "    try:\n",
    "        if 'GB' in val: return float(val.replace('GB','').strip()) * 1024\n",
    "        if 'KB' in val: return float(val.replace('KB','').strip()) / 1024\n",
    "        if 'B' in val: return 0.01 \n",
    "        return float(val.replace('MB','').strip())\n",
    "    except: return 0.0\n",
    "\n",
    "df['size_mb'] = df['size'].apply(standardize_size_to_mb)\n",
    "\n",
    "# Weighted Medals (Establishing a quality relationship: Gold=5, Silver=3, Bronze=1)\n",
    "medal_map = {'Gold': 5, 'Silver': 3, 'Bronze': 1, 'No Medal': 0}\n",
    "df['medal_points'] = df['Medals'].map(medal_map).fillna(0)\n",
    "\n",
    "# Handling Missing Usability (Noise removal using median imputation)\n",
    "df['Usability'] = df['Usability'].fillna(df['Usability'].median())\n",
    "\n",
    "# ==========================================\n",
    "# 3. PORTFOLIO AGGREGATION (Repeated Authors)\n",
    "# ==========================================\n",
    "# We treat the author's total history as their \"Resume\"\n",
    "authors = df.groupby('Author_name').agg({\n",
    "    'Dataset_name': 'count',      # Volume of projects\n",
    "    'No_of_files': 'sum',         # Total structural complexity\n",
    "    'Upvotes': 'sum',             # Total community impact\n",
    "    'Usability': 'mean',          # Average documentation quality\n",
    "    'medal_points': 'sum',        # Total peer validation\n",
    "    'size_mb': 'sum'              # Total data scale managed\n",
    "}).reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 4. ML FEATURE SCALING & OUTLIER HANDLING\n",
    "# ==========================================\n",
    "# We use Log transformation (log1p) on highly skewed columns.\n",
    "# This prevents one \"viral\" dataset from outranking consistently good developers.\n",
    "authors['log_upvotes'] = np.log1p(authors['Upvotes'])\n",
    "authors['log_size'] = np.log1p(authors['size_mb'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "cols_to_scale = ['Dataset_name', 'No_of_files', 'log_upvotes', 'Usability', 'medal_points', 'log_size']\n",
    "authors_scaled = pd.DataFrame(scaler.fit_transform(authors[cols_to_scale]), columns=cols_to_scale)\n",
    "\n",
    "# ==========================================\n",
    "# 5. ROLE-BASED RELATIONSHIP LOGIC\n",
    "# ==========================================\n",
    "\n",
    "# DEVELOPER Index: Documentation Consistency + Project Volume\n",
    "# Relationship: Clean hand-off capability.\n",
    "authors['Developer_Score'] = (authors_scaled['Usability'] * 0.7) + (authors_scaled['Dataset_name'] * 0.3)\n",
    "\n",
    "# SENIOR DEVELOPER Index: Industry Validation + Peer Impact\n",
    "# Relationship: Technical authority via community vetting.\n",
    "authors['Senior_Developer_Score'] = (authors_scaled['medal_points'] * 0.6) + (authors_scaled['log_upvotes'] * 0.4)\n",
    "\n",
    "# SOLUTION ARCHITECT Index: Complexity + Data Scale + Usability\n",
    "# Relationship: Ability to organize massive datasets without losing structure.\n",
    "authors['Solution_Architect_Score'] = (authors_scaled['No_of_files'] * 0.4) + (authors_scaled['log_size'] * 0.4) + (authors_scaled['Usability'] * 0.2)\n",
    "\n",
    "# ==========================================\n",
    "# 6. FINAL OUTPUT & REASONING ENGINE\n",
    "# ==========================================\n",
    "\n",
    "def get_reasoning(role, row):\n",
    "    if role == \"Developer\":\n",
    "        return (f\"Selected for high documentation standards. Maintained an average Usability score \"\n",
    "                f\"of {row['Usability']:.1f}/10 across {int(row['Dataset_name'])} projects, ensuring clean code handovers.\")\n",
    "    \n",
    "    if role == \"Senior Developer\":\n",
    "        return (f\"Selected for community authority and peer vetting. Earned {int(row['medal_points'])} medal points \"\n",
    "                f\"and {int(row['Upvotes'])} peer upvotes, establishing them as a gold-standard reference in the industry.\")\n",
    "    \n",
    "    if role == \"Solution Architect\":\n",
    "        # Check if size is large enough to show in GB\n",
    "        size_val = row['size_mb'] / 1024 if row['size_mb'] > 1024 else row['size_mb']\n",
    "        unit = \"GB\" if row['size_mb'] > 1024 else \"MB\"\n",
    "        return (f\"Selected for scale mastery and structural complexity. Successfully managed {int(row['No_of_files'])} \"\n",
    "                f\"individual files across a total footprint of {size_val:.1f} {unit} data.\")\n",
    "\n",
    "roles = [(\"Developer\", \"Developer_Score\"), \n",
    "         (\"Senior Developer\", \"Senior_Developer_Score\"), \n",
    "         (\"Solution Architect\", \"Solution_Architect_Score\")]\n",
    "\n",
    "for role_label, score_col in roles:\n",
    "    print(f\"\\n{'#'*80}\\nTOP 3 {role_label.upper()} CANDIDATES\\n{'#'*80}\")\n",
    "    # Sort by calculated ML Score and take Top 3\n",
    "    top_3 = authors.sort_values(score_col, ascending=False).head(3)\n",
    "    \n",
    "    for i, (_, row) in enumerate(top_3.iterrows()):\n",
    "        print(f\"{i+1}. {row['Author_name']}\")\n",
    "        print(f\"   BASIS: {get_reasoning(role_label, row)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
